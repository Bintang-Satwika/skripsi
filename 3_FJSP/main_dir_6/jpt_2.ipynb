{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial State:\n",
      "[[ 3  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11  1  3  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "\n",
      "Step 1, Actions: [3 3 3]\n",
      "Next State:\n",
      "[[ 3  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11  1  3  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Reward: [-1 -1 -1]\n",
      "Agent 1 at pos 3: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 2 at pos 7: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 3 at pos 11: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Conveyor: --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> ---\n",
      "Buffer: []\n",
      "Completed Products: []\n",
      "\n",
      "Step 2, Actions: [1 1 0]\n",
      "FAILED ACTION: No job available in window for WAIT\n",
      "FAILED ACTION: No job available in window for WAIT\n",
      "FAILED ACTION: Agent status not idle or job not ready (ACCEPT)\n",
      "Next State:\n",
      "[[ 3  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11  1  3  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Reward: [-1 -1 -1]\n",
      "Agent 1 at pos 3: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 2 at pos 7: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 3 at pos 11: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Conveyor: --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> ---\n",
      "Buffer: []\n",
      "Completed Products: []\n",
      "\n",
      "Step 3, Actions: [1 0 0]\n",
      "FAILED ACTION: No job available in window for WAIT\n",
      "FAILED ACTION: Agent status not idle or job not ready (ACCEPT)\n",
      "FAILED ACTION: Agent status not idle or job not ready (ACCEPT)\n",
      "Next State:\n",
      "[[ 3  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11  1  3  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Reward: [-1 -1 -1]\n",
      "Agent 1 at pos 3: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 2 at pos 7: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 3 at pos 11: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Conveyor: --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> ---\n",
      "Buffer: []\n",
      "Completed Products: []\n",
      "\n",
      "Step 4, Actions: [2 0 4]\n",
      "FAILED ACTION: No job available in window for WAIT\n",
      "FAILED ACTION: Agent status not idle or job not ready (ACCEPT)\n",
      "Next State:\n",
      "[[ 3  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11  1  3  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Reward: [-1 -1 -1]\n",
      "Agent 1 at pos 3: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 2 at pos 7: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 3 at pos 11: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Conveyor: --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> ---\n",
      "Buffer: []\n",
      "Completed Products: []\n",
      "\n",
      "Step 5, Actions: [2 4 2]\n",
      "FAILED ACTION: No job available in window for WAIT\n",
      "FAILED ACTION: No job available in window for WAIT\n",
      "Next State:\n",
      "[[ 3  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 7  2  3  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [11  1  3  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "Reward: [-1 -1 -1]\n",
      "Agent 1 at pos 3: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 2 at pos 7: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Agent 3 at pos 11: Status 0\n",
      "Window product: [None None None] Workbench: {}\n",
      "Conveyor: --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> --- <-> ---\n",
      "Buffer: ['C-1']\n",
      "Completed Products: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import sys\n",
    "\n",
    "# =============================================================================\n",
    "# Agent class (represents a robot with a workbench)\n",
    "# =============================================================================\n",
    "class Agent:\n",
    "    def __init__(self, agent_id: int, position: int, operation_capability: list, speed: float, window_size: int, num_agent: int):\n",
    "        self.window_size = window_size  # Window size as defined in the paper\n",
    "        # --- State attributes according to the paper ---\n",
    "        # Observation vector: [yᵣ, Oᵣ (2 values), O₍r,t₎, Zₜ (3 values), Ŝ₍yᵣ,t₎, Ŝ₍yᵣ₋1,t₎, Ŝ₍yᵣ₋2,t₎, pick_product_window]\n",
    "        # Total dimension: 1 + 2 + 1 + 3 + 3 + 1 = 11; however, here we add two groups (first and second product operations)\n",
    "        # as separate 3-dim vectors so the total becomes 1+2+1+3+3+3+1 = 14.\n",
    "        self.position = position  # Fixed position (yᵣ) on the conveyor (0-indexed)\n",
    "        self.operation_capability = operation_capability  # e.g. [1, 2]\n",
    "        self.operation_now = 0  # O₍r,t₎: current operation; 0 means idle.\n",
    "        self.status_all = [0] * num_agent  # Zₜ: status for all agents; 0: idle, 1: accept, 2: working, 3: completing.\n",
    "        self.first_product_operation = [0] * window_size  # Ŝ₍yᵣ,t₎, Ŝ₍yᵣ₋1,t₎, ... (for first operation)\n",
    "        self.second_product_operation = [0] * window_size  # For second operation\n",
    "        self.pick_product_window = 0  # Indicates which window section is targeted (if waiting)\n",
    "        self.many_operations = 2  # For this example, each job has two operations.\n",
    "\n",
    "        # Fixed properties\n",
    "        self.id = agent_id\n",
    "        self.speed = speed\n",
    "        self.processing_time_remaining = 0\n",
    "\n",
    "        # Buffers used when transferring jobs\n",
    "        self.workbench = {}  # Dictionary holding the job transferred to workbench\n",
    "        self.window_product = [None] * window_size  # The jobs observed in the agent's window\n",
    "        self.buffer_job_to_workbench = {}  # Buffer to temporarily hold job from conveyor\n",
    "        self.buffer_job_to_conveyor = {}  # Not used extensively here\n",
    "\n",
    "    def build_state(self):\n",
    "        \"\"\"\n",
    "        Build the state vector as a numpy array.\n",
    "        The state vector order is:\n",
    "          [position, operation_capability (2), operation_now, status_all (3),\n",
    "           first_product_operation (window_size=3), second_product_operation (window_size=3),\n",
    "           pick_product_window]\n",
    "        Total dimension = 1+2+1+3+3+3+1 = 14.\n",
    "        \"\"\"\n",
    "        return np.hstack([\n",
    "            np.array([self.position]),\n",
    "            np.array(self.operation_capability),\n",
    "            np.array([self.operation_now]),\n",
    "            np.array(self.status_all),\n",
    "            np.array(self.first_product_operation),\n",
    "            np.array(self.second_product_operation),\n",
    "            np.array([self.pick_product_window])\n",
    "        ])\n",
    "\n",
    "    def processing_time(self, base_processing_time):\n",
    "        return int(np.ceil(base_processing_time / self.speed))\n",
    "\n",
    "# =============================================================================\n",
    "# CircularConveyor class\n",
    "# =============================================================================\n",
    "class CircularConveyor:\n",
    "    def __init__(self, num_sections: int, max_capacity: float, arrival_rate: float, num_agents: int, n_jobs: int, current_episode_count: int):\n",
    "        self.num_sections = num_sections  # Total sections on the conveyor\n",
    "        self.max_capacity = max_capacity  # Fill capacity fraction (e.g. 0.75)\n",
    "        self.arrival_rate = arrival_rate  # Not used in full detail here.\n",
    "        self.conveyor = [None] * num_sections  # Initialize the conveyor with empty slots (None)\n",
    "        self.buffer_jobs = []  # Jobs waiting when the entry is full\n",
    "        self.total_jobs = {\"A\": 0, \"B\": 0, \"C\": 0}  # Count jobs for each product\n",
    "        # Define product operation sequences (each product has two operations)\n",
    "        self.product_operations = {\n",
    "            \"A\": [1, 2],\n",
    "            \"B\": [2, 3],\n",
    "            \"C\": [1, 3],\n",
    "        }\n",
    "        self.job_details = {}  # For each job label, store its list of remaining operations\n",
    "        self.product_completed = []  # List of completed product job labels.\n",
    "        self.n_jobs = n_jobs\n",
    "        self.sum_n_jobs = 0\n",
    "        self.num_agents = num_agents\n",
    "        self.iteration = 0\n",
    "        self.episode = current_episode_count\n",
    "        self.episode_seed = 0\n",
    "\n",
    "    def add_job(self, product_type: str):\n",
    "        \"\"\"Add a new job to the buffer (if capacity permits) with its operation sequence.\"\"\"\n",
    "        self.total_jobs[product_type] += 1\n",
    "        job_label = f\"{product_type}-{self.total_jobs[product_type]}\"\n",
    "        # Create a copy of the operation list.\n",
    "        self.job_details[job_label] = self.product_operations[product_type][:]\n",
    "        self.buffer_jobs.append(job_label)\n",
    "\n",
    "    def move_conveyor(self):\n",
    "        \"\"\"Move jobs forward in a circular manner.\"\"\"\n",
    "        last_job = self.conveyor[-1]\n",
    "        for i in range(self.num_sections - 1, 0, -1):\n",
    "            self.conveyor[i] = self.conveyor[i - 1]\n",
    "        self.conveyor[0] = last_job\n",
    "        # Load a job from the buffer if conditions are met.\n",
    "        if (self.buffer_jobs and \n",
    "            sum(1 for x in self.conveyor if x is not None) < self.max_capacity * self.num_sections and \n",
    "            self.conveyor[0] is None and \n",
    "            sum(1 for x in self.conveyor if x is None) > self.num_agents):\n",
    "            self.conveyor[0] = self.buffer_jobs.pop(0)\n",
    "\n",
    "    def generate_jobs(self):\n",
    "        \"\"\"Generate new jobs based on a simplified Poisson process.\"\"\"\n",
    "        if self.sum_n_jobs < self.n_jobs:\n",
    "            self.iteration += 1\n",
    "            new_job = 1 if self.iteration % 5 == 0 else 0\n",
    "            if new_job == 1:\n",
    "                allowed_types = [ptype for ptype in self.total_jobs if self.total_jobs[ptype] < 7]\n",
    "                if not allowed_types:\n",
    "                    return\n",
    "                random.seed(int(self.episode_seed + self.iteration))\n",
    "                product_type = random.choice(allowed_types)\n",
    "                self.sum_n_jobs += 1\n",
    "                self.add_job(product_type)\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display the conveyor, buffer, and completed products.\"\"\"\n",
    "        conveyor_state = \" <-> \".join([str(j) if j is not None else \"---\" for j in self.conveyor])\n",
    "        print(\"Conveyor:\", conveyor_state)\n",
    "        print(\"Buffer:\", self.buffer_jobs)\n",
    "        print(\"Completed Products:\", self.product_completed)\n",
    "\n",
    "# =============================================================================\n",
    "# FJSPEnv: Gymnasium Environment for Flexible Job Shop Scheduling\n",
    "# =============================================================================\n",
    "class FJSPEnv(gym.Env):\n",
    "    def __init__(self, window_size: int, num_agents: int, max_steps: int, episode: int):\n",
    "        super(FJSPEnv, self).__init__()\n",
    "        self.episode_count = episode\n",
    "        self.window_size = window_size\n",
    "        self.num_agents = num_agents\n",
    "        self.max_steps = max_steps\n",
    "        self.step_count = 0\n",
    "\n",
    "        # Flags for rewards and action outcomes\n",
    "        self.is_action_wait_succeed = [False] * num_agents\n",
    "        self.is_status_working_succeed = [False] * num_agents\n",
    "        self.is_job_moving_to_workbench = [False] * num_agents\n",
    "        self.product_return_to_conveyor = [False] * num_agents\n",
    "        self.total_process_done = 0\n",
    "        self.reward_product_complete = 0\n",
    "\n",
    "        # Conveyor parameters\n",
    "        self.num_sections = 12\n",
    "        self.max_capacity = 0.75\n",
    "        self.arrival_rate = 0.4\n",
    "        self.n_jobs = 21\n",
    "\n",
    "        # Agent configuration (fixed positions on the conveyor)\n",
    "        self.agent_positions = [3, 3 + 1 + window_size, 3 + 1*2 + window_size*2]\n",
    "        self.agent_operation_capability = [[1, 2], [2, 3], [1, 3]]\n",
    "        # Define state vector index positions (must sum to 14 dimensions per agent)\n",
    "        # Order: [position, O_capability (indices 1-2), operation_now (index 3), status_all (indices 4-6),\n",
    "        #         first job op window (indices 7-9), second job op window (indices 10-12), pick_product_window (index 13)]\n",
    "        self.state_yr_location = 0\n",
    "        self.state_operation_capability_location = [1, 2]\n",
    "        self.state_operation_now_location = 3\n",
    "        self.state_status_location_all = [4, 5, 6]  # one for each agent; each agent’s own status is at its designated index.\n",
    "        self.state_first_job_operation_location = [7, 8, 9]  # for window: yr, yr-1, yr-2\n",
    "        self.state_second_job_operation_location = [10, 11, 12]  # similarly for second operation\n",
    "        self.state_pick_job_window_location = 13\n",
    "\n",
    "        self.agent_many_operations = 2\n",
    "        self.agent_speeds = [1, 2, 3]  # Speeds for agent 1,2,3 respectively.\n",
    "        self.base_processing_times = [24, 18, 12]  # Base processing times for operations (indexed by op-1)\n",
    "\n",
    "        self.agents = []\n",
    "        self.FAILED_ACTION = False\n",
    "\n",
    "        # Observation space: each agent has a 14-dimensional state vector.\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.num_agents, 14), dtype=np.float32)\n",
    "        # Action space: 0=ACCEPT, 1=WAIT (target yr-1), 2=WAIT (target yr-2), 3=DECLINE, 4=CONTINUE.\n",
    "        self.action_space = spaces.MultiDiscrete([5] * self.num_agents)\n",
    "        self.state_dim = self.observation_space.shape\n",
    "        self.action_dim = 5\n",
    "\n",
    "    def initial_state(self):\n",
    "        obs = []\n",
    "        for agent in self.agents:\n",
    "            obs.append(agent.build_state())\n",
    "        self.observation_all = np.array(obs)\n",
    "        return self.observation_all\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.episode_count += 1\n",
    "        current_episode_count = self.episode_count\n",
    "        self.__init__(window_size=self.window_size, num_agents=self.num_agents, max_steps=self.max_steps, episode=current_episode_count)\n",
    "        self.episode_count = current_episode_count\n",
    "        self.step_count = 0\n",
    "        self.conveyor = CircularConveyor(self.num_sections, self.max_capacity, self.arrival_rate,\n",
    "                                          self.num_agents, n_jobs=self.n_jobs, current_episode_count=self.episode_count)\n",
    "        self.agents = []\n",
    "        for i in range(self.num_agents):\n",
    "            agent = Agent(\n",
    "                agent_id=i+1,\n",
    "                position=self.agent_positions[i],\n",
    "                operation_capability=self.agent_operation_capability[i],\n",
    "                speed=self.agent_speeds[i],\n",
    "                window_size=self.window_size,\n",
    "                num_agent=self.num_agents,\n",
    "            )\n",
    "            self.agents.append(agent)\n",
    "        return self.initial_state(), {}\n",
    "\n",
    "    # ---------------------- Action Functions ---------------------------\n",
    "    def action_accept(self, observation, agent, i, status_index):\n",
    "        \"\"\"\n",
    "        ACCEPT:\n",
    "          - If agent is idle (operation_now==0) and no job in workbench,\n",
    "            then if the job is in the conveyor at agent’s position (pick_product_window==1),\n",
    "            move it to workbench and update status from 0 -> 1 -> 2.\n",
    "        \"\"\"\n",
    "        if observation[self.state_operation_now_location] == 0 and not agent.workbench:\n",
    "            if observation[status_index] == 1 and self.is_job_moving_to_workbench[i]:\n",
    "                # Job already moved to workbench\n",
    "                self.is_job_moving_to_workbench[i] = False\n",
    "                agent.workbench = agent.buffer_job_to_workbench.copy()\n",
    "                agent.buffer_job_to_workbench = {}\n",
    "                observation[self.state_pick_job_window_location] = 0\n",
    "                observation[status_index] = 2  # now working\n",
    "                # Get the first operation from the buffered job details\n",
    "                list_operation = list(agent.workbench.values())[0]\n",
    "                # Check if the job's first operation is in agent's capability:\n",
    "                if list_operation[0] in agent.operation_capability:\n",
    "                    select_operation = list_operation[0]\n",
    "                    observation[self.state_operation_now_location] = select_operation\n",
    "                    # Clear the job's operations from the conveyor window for this agent:\n",
    "                    observation[self.state_first_job_operation_location[0]] = 0\n",
    "                    observation[self.state_second_job_operation_location[0]] = 0\n",
    "                    agent.processing_time_remaining = agent.processing_time(self.base_processing_times[select_operation - 1])\n",
    "                else:\n",
    "                    print(\"FAILED ACTION: Capability mismatch in workbench (ACCEPT)\")\n",
    "                    self.FAILED_ACTION = True\n",
    "            elif observation[status_index] == 0 and observation[self.state_pick_job_window_location] == 1 and not self.is_job_moving_to_workbench[i]:\n",
    "                # Job is still on the conveyor at agent's position.\n",
    "                if observation[self.state_first_job_operation_location[0]] in agent.operation_capability:\n",
    "                    observation[status_index] = 1  # set to accept\n",
    "                    self.is_job_moving_to_workbench[i] = True\n",
    "                    # Buffer the job from the conveyor based on the agent's observed window.\n",
    "                    agent.buffer_job_to_workbench[str(agent.window_product[0])] = self.conveyor.job_details.get(agent.window_product[0], [])\n",
    "                    # Remove job from the conveyor at the agent's position:\n",
    "                    self.conveyor.conveyor[agent.position] = None\n",
    "                else:\n",
    "                    print(\"FAILED ACTION: Job operation not in agent capability (ACCEPT)\")\n",
    "                    self.FAILED_ACTION = True\n",
    "            else:\n",
    "                print(\"FAILED ACTION: Agent status not idle or job not ready (ACCEPT)\")\n",
    "                self.FAILED_ACTION = True\n",
    "        else:\n",
    "            print(\"FAILED ACTION: Workbench not empty (ACCEPT)\")\n",
    "            self.FAILED_ACTION = True\n",
    "        return observation, agent\n",
    "\n",
    "    def action_wait(self, observation, agent, i, status_index, actions):\n",
    "        \"\"\"\n",
    "        WAIT:\n",
    "          - When agent is idle, if a job exists in the window (for yr-1 or yr-2),\n",
    "            then set pick_product_window accordingly.\n",
    "        \"\"\"\n",
    "        if observation[status_index] == 0:\n",
    "            if observation[self.state_first_job_operation_location[1]] != 0 and actions[i] == 1:\n",
    "                observation[self.state_pick_job_window_location] = 1\n",
    "                self.is_action_wait_succeed[i] = True\n",
    "            elif observation[self.state_first_job_operation_location[2]] != 0 and actions[i] == 2:\n",
    "                observation[self.state_pick_job_window_location] = 2\n",
    "                self.is_action_wait_succeed[i] = True\n",
    "            else:\n",
    "                print(\"FAILED ACTION: No job available in window for WAIT\")\n",
    "                self.FAILED_ACTION = True\n",
    "        else:\n",
    "            print(\"FAILED ACTION: Agent status not idle for WAIT\")\n",
    "            self.FAILED_ACTION = True\n",
    "        return observation, agent\n",
    "\n",
    "    def action_decline(self, observation, agent, i, status_index):\n",
    "        \"\"\"\n",
    "        DECLINE:\n",
    "          - Reset the pick_product_window to 0.\n",
    "        \"\"\"\n",
    "        observation[self.state_pick_job_window_location] = 0\n",
    "        return observation, agent\n",
    "\n",
    "    def action_continue(self, observation, agent, i, status_index):\n",
    "        \"\"\"\n",
    "        CONTINUE:\n",
    "          A. If agent is working (status==2), decrement processing time.\n",
    "             If processing time becomes 0, transition status to completing (3).\n",
    "          B. If agent is idle (status==0) or still in accept (1), no change.\n",
    "        \"\"\"\n",
    "        if observation[status_index] == 2 and observation[self.state_operation_now_location] != 0 and agent.workbench:\n",
    "            self.is_status_working_succeed[i] = True\n",
    "            if agent.processing_time_remaining > 0:\n",
    "                agent.processing_time_remaining -= 1\n",
    "            elif agent.processing_time_remaining == 0:\n",
    "                observation[status_index] = 3  # completing\n",
    "                self.is_status_working_succeed[i] = False\n",
    "                self.total_process_done += 1\n",
    "            else:\n",
    "                print(\"FAILED ACTION: Processing time error in CONTINUE\")\n",
    "                self.FAILED_ACTION = True\n",
    "        elif observation[status_index] == 1:\n",
    "            # Remain in accept state until workbench transfer occurs.\n",
    "            pass\n",
    "        return observation, agent\n",
    "\n",
    "    # ---------------------- State Update Function ---------------------------\n",
    "    def update_state(self, observation_all, actions):\n",
    "        next_observation_all = observation_all.copy()\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            # Use agent.position as the fixed reference for the window.\n",
    "            current_pos = agent.position\n",
    "            # Compute window indices (circularly): [yr, yr-1, yr-2]\n",
    "            window_sections = [(current_pos - r) % self.num_sections for r in range(self.window_size)]\n",
    "            agent.window_product = np.array(self.conveyor.conveyor)[window_sections]\n",
    "            self.is_action_wait_succeed[i] = False\n",
    "            self.is_status_working_succeed[i] = False\n",
    "\n",
    "            observation = observation_all[i]\n",
    "            # For each agent, we assume its own status is stored at an index in status_all.\n",
    "            # Here we use self.state_status_location_all[i] as the agent’s own status.\n",
    "            status_index = self.state_status_location_all[i]\n",
    "\n",
    "            # Process the action for this agent.\n",
    "            if actions[i] == 0:  # ACCEPT\n",
    "                observation, agent = self.action_accept(observation, agent, i, status_index)\n",
    "            elif actions[i] in [1, 2]:  # WAIT actions for yr-1 (action==1) and yr-2 (action==2)\n",
    "                observation, agent = self.action_wait(observation, agent, i, status_index, actions)\n",
    "            elif actions[i] == 3:  # DECLINE\n",
    "                observation, agent = self.action_decline(observation, agent, i, status_index)\n",
    "            elif actions[i] == 4:  # CONTINUE\n",
    "                observation, agent = self.action_continue(observation, agent, i, status_index)\n",
    "\n",
    "            # RETURN TO CONVEYOR logic:\n",
    "            if self.product_return_to_conveyor[i] and agent.workbench:\n",
    "                if self.conveyor.conveyor[agent.position] is None:\n",
    "                    self.conveyor.conveyor[agent.position] = str(list(agent.workbench)[0])\n",
    "                    self.product_return_to_conveyor[i] = False\n",
    "                    agent.workbench = {}\n",
    "                    observation[status_index] = 0\n",
    "                    observation[self.state_operation_now_location] = 0\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            # If status is completing (3) and workbench not empty, update job details.\n",
    "            if observation[status_index] == 3 and not self.product_return_to_conveyor[i]:\n",
    "                for key, op_list in agent.workbench.items():\n",
    "                    if len(op_list) > 1:\n",
    "                        agent.workbench[key].pop(0)\n",
    "                    else:\n",
    "                        self.conveyor.product_completed.append(key)\n",
    "                        agent.workbench = {}\n",
    "                        observation[status_index] = 0\n",
    "                        observation[self.state_operation_now_location] = 0\n",
    "                    if agent.workbench:\n",
    "                        if list(agent.workbench.values())[0][0] in agent.operation_capability:\n",
    "                            self.product_return_to_conveyor[i] = False\n",
    "                            observation[status_index] = 2\n",
    "                            observation[self.state_operation_now_location] = list(agent.workbench.values())[0][0]\n",
    "                        else:\n",
    "                            self.product_return_to_conveyor[i] = True\n",
    "                    try:\n",
    "                        self.conveyor.job_details[key] = agent.workbench[key]\n",
    "                    except:\n",
    "                        self.conveyor.job_details.pop(key)\n",
    "            # If no operations in first job window, reset pick_product_window.\n",
    "            if np.sum(observation[self.state_first_job_operation_location]) == 0:\n",
    "                observation[self.state_pick_job_window_location] = 0\n",
    "\n",
    "            self.agents[i] = agent\n",
    "            next_observation_all[i] = observation\n",
    "\n",
    "        # After processing all agents, update the conveyor.\n",
    "        self.conveyor.move_conveyor()\n",
    "        self.conveyor.generate_jobs()\n",
    "\n",
    "        # Update the window parts of the state for each agent.\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            window_sections = [(agent.position - r) % self.num_sections for r in range(self.window_size)]\n",
    "            agent.window_product = np.array(self.conveyor.conveyor)[window_sections]\n",
    "            for j, pos in enumerate(window_sections):\n",
    "                job_label = self.conveyor.conveyor[pos]\n",
    "                job_details_value = self.conveyor.job_details.get(job_label, [])\n",
    "                next_observation_all[i, self.state_first_job_operation_location[j]] = job_details_value[0] if len(job_details_value) > 0 else 0\n",
    "                next_observation_all[i, self.state_second_job_operation_location[j]] = job_details_value[1] if len(job_details_value) > 1 else 0\n",
    "\n",
    "        return next_observation_all\n",
    "\n",
    "    def step(self, actions):\n",
    "        \"\"\"\n",
    "        Step function:\n",
    "         - actions: an array of length num_agents, where each action is in {0,1,2,3,4}\n",
    "           0: ACCEPT, 1: WAIT (target yr-1), 2: WAIT (target yr-2), 3: DECLINE, 4: CONTINUE.\n",
    "        \"\"\"\n",
    "        self.is_action_wait_succeed = [False] * self.num_agents\n",
    "        self.is_status_working_succeed = [False] * self.num_agents\n",
    "        self.reward_product_complete = 0\n",
    "        self.step_count += 1\n",
    "\n",
    "        next_observation_all = self.update_state(self.observation_all, actions)\n",
    "\n",
    "        reward_wait_all = self.reward_wait(actions, self.is_action_wait_succeed)\n",
    "        reward_working_all = self.reward_working(self.observation_all, self.is_status_working_succeed)\n",
    "        reward_step_all = self.reward_complete()\n",
    "        reward_agent_all = -1 + reward_wait_all + reward_working_all + reward_step_all\n",
    "\n",
    "        done_step = self.step_count >= self.max_steps\n",
    "        truncated_step = True if len(self.conveyor.product_completed) >= self.n_jobs else False\n",
    "        self.observation_all = next_observation_all\n",
    "        info_step = {\"actions\": actions}\n",
    "        return next_observation_all, reward_agent_all, done_step, truncated_step, info_step\n",
    "\n",
    "    def reward_wait(self, actions, is_action_wait_succeed, k_wait=1):\n",
    "        rewards = []\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            if (actions[i] in [1, 2]) and is_action_wait_succeed[i]:\n",
    "                factor_x = 2.0 if actions[i] == 1 else 3.0\n",
    "                rewards.append(agent.speed / sum(np.multiply(factor_x, self.agent_speeds)))\n",
    "            else:\n",
    "                rewards.append(0)\n",
    "        return k_wait * np.array(rewards)\n",
    "\n",
    "    def reward_working(self, observations, is_status_working_succeed, k_working=4):\n",
    "        rewards = []\n",
    "        for r, agent in enumerate(self.agents):\n",
    "            obs = observations[r]\n",
    "            # Each agent's own status is stored at the corresponding index in state_status_location_all.\n",
    "            if obs[self.state_status_location_all[r]] == 2:\n",
    "                rewards.append(float(agent.speed) / float(sum(self.agent_speeds)))\n",
    "            else:\n",
    "                rewards.append(0)\n",
    "        return k_working * np.array(rewards)\n",
    "\n",
    "    def reward_complete(self, k_complete=4):\n",
    "        value = k_complete * self.total_process_done\n",
    "        self.total_process_done = 0\n",
    "        return value\n",
    "\n",
    "    def render(self):\n",
    "        for a, agent in enumerate(self.agents):\n",
    "            print(f\"Agent {agent.id} at pos {int(self.observation_all[a][0])}: Status {int(self.observation_all[a][self.state_status_location_all[a]])}\")\n",
    "            print(\"Window product:\", agent.window_product, \"Workbench:\", agent.workbench)\n",
    "        self.conveyor.display()\n",
    "\n",
    "# =============================================================================\n",
    "# Main function to test the environment\n",
    "# =============================================================================\n",
    "def main():\n",
    "    # Create environment with window_size=3, 3 agents, max_steps=20, episode=1.\n",
    "    env = FJSPEnv(window_size=3, num_agents=3, max_steps=20, episode=1)\n",
    "    state, _ = env.reset()\n",
    "    print(\"Initial State:\")\n",
    "    print(state)\n",
    "    \n",
    "    done = False\n",
    "    steps = 0\n",
    "    # For testing, we sample random actions from the defined action space.\n",
    "    while not done and steps < 5:\n",
    "        # For each agent, sample an action (0-4)\n",
    "        actions = env.action_space.sample()\n",
    "        print(f\"\\nStep {steps+1}, Actions: {actions}\")\n",
    "        next_state, reward, done, truncated, info = env.step(actions)\n",
    "        print(\"Next State:\")\n",
    "        print(next_state)\n",
    "        print(\"Reward:\", reward)\n",
    "        env.render()\n",
    "        steps += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "episode: 1\n",
      "0\n",
      "Episode complete. Total Reward: 117.80555555555557 jumlah step: 193 total product completed: 21\n",
      "\n",
      "episode: 2\n",
      "1\n",
      "Episode complete. Total Reward: 111.49074074074073 jumlah step: 220 total product completed: 21\n",
      "\n",
      "episode: 3\n",
      "2\n",
      "Episode complete. Total Reward: 101.79629629629632 jumlah step: 220 total product completed: 21\n",
      "\n",
      "episode: 4\n",
      "3\n",
      "Episode complete. Total Reward: 104.888888888889 jumlah step: 209 total product completed: 21\n",
      "\n",
      "episode: 5\n",
      "4\n",
      "Episode complete. Total Reward: 119.78703703703697 jumlah step: 209 total product completed: 21\n",
      "\n",
      "episode: 6\n",
      "5\n",
      "Episode complete. Total Reward: 114.49074074074065 jumlah step: 217 total product completed: 21\n",
      "\n",
      "episode: 7\n",
      "6\n",
      "Episode complete. Total Reward: 118.4166666666666 jumlah step: 213 total product completed: 21\n",
      "\n",
      "episode: 8\n",
      "7\n",
      "Episode complete. Total Reward: 114.46296296296303 jumlah step: 200 total product completed: 21\n",
      "\n",
      "episode: 9\n",
      "8\n",
      "Episode complete. Total Reward: 113.70370370370374 jumlah step: 194 total product completed: 21\n",
      "\n",
      "episode: 10\n",
      "9\n",
      "Episode complete. Total Reward: 106.52777777777783 jumlah step: 225 total product completed: 21\n",
      "\n",
      "episode: 11\n",
      "10\n",
      "Episode complete. Total Reward: 104.62037037037044 jumlah step: 213 total product completed: 21\n",
      "\n",
      "episode: 12\n",
      "11\n",
      "Episode complete. Total Reward: 135.15740740740722 jumlah step: 184 total product completed: 21\n",
      "\n",
      "episode: 13\n",
      "12\n",
      "Episode complete. Total Reward: 123.02777777777779 jumlah step: 202 total product completed: 21\n",
      "\n",
      "episode: 14\n",
      "13\n",
      "Episode complete. Total Reward: 125.75000000000001 jumlah step: 189 total product completed: 21\n",
      "\n",
      "episode: 15\n",
      "14\n",
      "Episode complete. Total Reward: 128.76851851851848 jumlah step: 186 total product completed: 21\n",
      "\n",
      "episode: 16\n",
      "15\n",
      "Episode complete. Total Reward: 120.5 jumlah step: 204 total product completed: 21\n",
      "\n",
      "episode: 17\n",
      "16\n",
      "Episode complete. Total Reward: 133.10185185185185 jumlah step: 186 total product completed: 21\n",
      "\n",
      "episode: 18\n",
      "17\n",
      "Episode complete. Total Reward: 108.63888888888896 jumlah step: 209 total product completed: 21\n",
      "\n",
      "episode: 19\n",
      "18\n",
      "Episode complete. Total Reward: 95.13888888888914 jumlah step: 222 total product completed: 21\n",
      "\n",
      "episode: 20\n",
      "19\n",
      "Episode complete. Total Reward: 114.77777777777786 jumlah step: 210 total product completed: 21\n",
      "rewards: {1: 117.80555555555557, 2: 111.49074074074073, 3: 101.79629629629632, 4: 104.888888888889, 5: 119.78703703703697, 6: 114.49074074074065, 7: 118.4166666666666, 8: 114.46296296296303, 9: 113.70370370370374, 10: 106.52777777777783, 11: 104.62037037037044, 12: 135.15740740740722, 13: 123.02777777777779, 14: 125.75000000000001, 15: 128.76851851851848, 16: 120.5, 17: 133.10185185185185, 18: 108.63888888888896, 19: 95.13888888888914, 20: 114.77777777777786}\n",
      "makespan: {1: 193, 2: 220, 3: 220, 4: 209, 5: 209, 6: 217, 7: 213, 8: 200, 9: 194, 10: 225, 11: 213, 12: 184, 13: 202, 14: 189, 15: 186, 16: 204, 17: 186, 18: 209, 19: 222, 20: 210}\n"
     ]
    }
   ],
   "source": [
    "from RULED_BASED import MASKING_action,  FCFS_action, RANDOM_action, HITL_action\n",
    "if __name__ == \"__main__\":\n",
    "    env = FJSPEnv(window_size=3, num_agents=3, max_steps=1000, episode=1)\n",
    "    rewards = {}\n",
    "    makespan = {}\n",
    "    episode_seed=0\n",
    "    for episode in range(1, 20+1):\n",
    "        print(\"\\nepisode:\", episode)\n",
    "        state, info = env.reset(seed=1000+episode)\n",
    "        if (episode-1) %1 == 0:\n",
    "            episode_seed= episode-1\n",
    "\n",
    "        env.conveyor.episode_seed= episode_seed\n",
    "        print(env.conveyor.episode_seed)\n",
    "        reward_satu_episode = 0\n",
    "        done = False\n",
    "        truncated = False\n",
    "        #print(\"\\nEpisode:\", episode)\n",
    "        #print(\"Initial state:\", state)\n",
    "        while not done and not truncated: \n",
    "            if len(env.conveyor.product_completed)>= env.n_jobs:\n",
    "                print(\"All jobs are completed.\")\n",
    "                break\n",
    "\n",
    "            actions, masking=HITL_action(state, env)\n",
    "            #actions=FCFS_action(state, env)\n",
    "\n",
    "            if None in actions:\n",
    "                print(\"FAILED ACTION: \", actions)\n",
    "                break\n",
    "\n",
    "\n",
    "            next_state, reward, done, truncated, info = env.step(actions)\n",
    "            reward = np.mean(reward)\n",
    "            reward_satu_episode += reward\n",
    "            \n",
    "            if env.FAILED_ACTION:\n",
    "                print(\"episode:\", episode)\n",
    "                print(\"state:\\n\", state)\n",
    "                print(\"actions:\", actions)\n",
    "                print(\"next_state:\\n\", next_state)\n",
    "                #print(env.observation_all)\n",
    "                #print(\"info:\", info)\n",
    "                print(\"FAILED ENV\")\n",
    "                break\n",
    "\n",
    "            state = next_state\n",
    "            #print(\"next_state:\", next_state)\n",
    "\n",
    "        # if  None in actions:\n",
    "        #     break\n",
    "\n",
    "        rewards[episode] = reward_satu_episode\n",
    "        makespan[episode] = env.step_count\n",
    "        print(\"Episode complete. Total Reward:\", reward_satu_episode, \"jumlah step:\", env.step_count, \"total product completed:\", len(env.conveyor.product_completed))\n",
    "        order = {'A': 0, 'B': 1, 'C': 2}\n",
    "\n",
    "\n",
    "    env.close()\n",
    "    print(\"rewards:\", rewards)\n",
    "    print(\"makespan:\", makespan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
